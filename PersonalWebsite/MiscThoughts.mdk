Prelude: DZPrelude
Title: Misc. Thoughts - David K. Zhang - Personal Website

[INCLUDE="DZMathDefs.mdk"]
[INCLUDE="DZHeader.html"]

~ Title { margin-bottom: 2em; }
#### Miscellaneous Thoughts
~

This page contains a disorganized collection of ideas that I'm learning and thinking about, but have yet to coalesce into a coherent narrative. Feel free to look around --- you might find something interesting!

-----

~ MathCard
~~ WellBody
**Problem:** How many edges does an icosahedron have?
~~
~~ BoxBody
_Note_: An icosahedron is a polyhedron (3D shape) that has 20 triangular faces.
~~
~

Obviously, we could solve this problem by drawing a picture of an icosahedron and counting the number of edges we see. However, we can also solve this problem in a _purely combinatorial_ fashion, by counting something in two different ways.

~ Box
_Solution_: Let's say that an _edge-face pair_ $(e, f)$ is an ordered pair consisting of a face $f$ and an edge $e$ which is incident to $f$. Since the faces of an icosahedron are triangular, each contributes three edge-face pairs. Hence, the number of edge-face pairs is $3\abs{F}.$ Similarly, each edge contributes two edge-face pairs, so the number of edge-face pairs is $2\abs{E}.$ This shows that $2\abs{E} = 3\abs{F},$ so an icosahedron has 30 edges.
~

This is a special case of a more general principle.

~ MathCard
~~ TheoremBody
Let $G$ be a bipartite graph with $n_L$ vertices on the left and $n_R$ vertices on the right. Suppose the vertices on the left all have degree $d_L,$ and the vertices on the right all have degree $d_R.$ Then $n_L d_L = n_R d_R.$
~~
~~ ProofBody
Both $n_L d_L$ and $n_R d_R$ count the number of edges in $G.$
~~
~


-----

~ Align
\vg_k &\coloneqq \nabla f(\vx_k) \\
H_k &\coloneqq \nabla^2 f(\vx_k) \\
\vs_k &\coloneqq \vx_k - \vx_{k-1} \\
\vy_k &\coloneqq \vg_k - \vg_{k-1}
~

~ Well
~~ Math { .mt-2; .mb-0; }
\vx_{k+1} = \vx_{k} - H_k^{-1} \vg_k
~~
~

Newton's method is the gold standard for local nonlinear optimization of smooth functions. However, for large-scale optimization problems, it can be very time-consuming to compute the exact Hessian matrix $H_k \coloneqq \nabla^2 f(\vx_k)$ and solve a linear system to obtain $H_k^{-1} \vg_k$. The idea of a ___quasi-Newton method___ is to substitute an approximation $B_k$ for the true Hessian $H_k$ which is good enough that we can still make progress, but easier to compute than the full matrix $\nabla^2 f(\vx_k)$ of second partial derivatives.

In order to develop this idea, we need to have a rigorous notion of what it means for $B_k$ to be "close enough" to $H_k.$ For example, one obvious way to define "close enough" would be to require that $\norm{B_k - H_k} < \eps$ in some suitably chosen matrix norm, such as the operator norm or Frobenius norm. This would be an unwise definition, because we would have to calculate the exact Hessian matrix $H_k$ in order to verify that $\norm{B_k - H_k}$ is small enough, when the whole idea of quasi-Newton methods was to avoid computing $H_k$ in the first place.

Instead, we will consider the _algebraic_ properties of $H_k,$ and declare $B_k$ to be "close enough" if it satisfies those same properties. The defining characteristic of the Hessian matrix $H_k$ is that it measures second-order change in the objective function $f,$ or equivalently, first-order change in its gradient $\nabla f.$

~ Align
\nabla f(\vx_{k-1}) &= \nabla f(\vx_k) + \qty[\nabla^2 f(\vx_k)] (\vx_{k-1} - \vx_k) + \cdots \\
\vg_{k-1} &= \vg_k + H_k (\vx_{k-1} - \vx_k) + \cdots \\
~

Discarding higher-order terms yields the approximate identity $\vy_k \approx H_k \vs_k.$ Since this is the defining property of the Hessian $H_k,$ it is natural that we ask our approximation $B_k$ to satisfy $\vy_k \approx B_k \vs_k.$ In the optimization literature, this is known as the ___secant equation___.

We also note that the Hessian matrix $H_k$ is symmetric (since partial derivative operators commute) and positive-definite (in a neighborhood of a local minimum). We will therefore require our approximation $B_k$ to also be symmetric and positive-definite.

Now, these three requirements (symmetry, positive-definiteness, and the secant equation) are far from enough to uniquely pin down a choice of $B_k.$ We will use our remaining degrees of freedom to pick a matrix $B_k$ which is _as easy as possible to work with_. Recall that it takes $O(n^3)$ time to solve a general $n \times n$ linear system in order to calculate $B_k^{-1} \vg_k.$ If we choose a matrix $B_k$ which has some special structure (e.g., a diagonal matrix), we can reduce the $O(n^3)$ cost to $O(n^2),$ or possibly even $O(n).$

The simplest possible choice of $B_k$ would be a positive scalar multiple of the identity matrix, $B_k \coloneqq \beta_k I.$ When $\beta_k > 0,$ this is certainly symmetric and positive-definite. However, unless $\vs_k$ and $\vy_k$ are parallel vectors (which will generally not be the case), there is very little hope that a scalar multiple of the identity matrix will be able to satisfy the secant equation $\vy_k = \beta_k \vs_k$. Nonetheless, we can still proceed by asking that the _error_ in the secant equation be as small as possible. That is, we determine the optimal value of $\beta_k$ by minimizing the squared Euclidean norm of the residual:

~ Math
\min_{\beta_k} \norm{\vy_k - \beta_k \vs_k}_2^2
~

This is a one-dimensional optimization problem which we can solve analytically by differentiating with respect to $\beta_k$ and setting the derivative equal to zero.

~ Align
0 &\overset{!}{=}
\pdv{\beta_k} \norm{\vy_k - \beta_k \vs_k}_2^2 \\
&= \pdv{\beta_k} \qty[(\vy_k - \beta_k \vs_k)^T (\vy_k - \beta_k \vs_k)] \\
&= \pdv{\beta_k} \qty[\vy_k^T \vy_k - 2 \beta_k \vs_k^T \vy_k + \beta_k^2 \vs_k^T \vs_k] \\
&= - 2 \vs_k^T \vy_k + 2\beta_k \vs_k^T \vs_k
~

~ Math
\implies\quad \beta_k = \frac{\vs_k^T \vy_k}{\vs_k^T \vs_k}
~

By plugging this optimal choice of $\beta_k$ into the quasi-Newton update equation $\vx_{k+1} = \vx_{k} - B_k^{-1} \vg_k$, we obtain the following iterative formula:

~ Well
~~ Math { .mt-2; .mb-0; }
\vx_{k+1} = \vx_k - \frac{\vs_k^T \vs_k}{\vs_k^T \vy_k} \vg_k
~~
~

This is called the [___Barzilai--Borwein method___](https://doi.org/10.1093/imanum/8.1.141), first published in 1988.

~ Box
**Aside:** Isn't it remarkable that these simple considerations have led us to the forefront of mathematical research within the last fifty years? To be clear, I say "simple" as opposed to "easy," because coming up with any idea for the first time is never easy. Nonetheless, we have reached this point without the need for divine inspiration or esoteric theorems of mathematical analysis. We started off on the right foot, made reasonable choices at each juncture, and arrived at a wildly successful discovery (the original Barzilai--Borwein paper has been cited over 2,400 times).
~

At this point, we pause to make an important observation. If we take the secant equation $\vy_k = B_k \vs_k$ and multiply both sides by $B_k^{-1}$, we arrive at the equivalent form $B_k^{-1} \vy_k = \vs_k.$ We will call this the ___dual secant equation___, and to clarify the distinction, we will call the original secant equation $\vy_k = B_k \vs_k$ the ___primal secant equation___. (Note that these names are not standardized in the nonlinear optimization literature.) Now, we just derived the Barzilai--Borwein method by determining the value of $\beta_k$ that minimizes the residual in the primal secant equation. What if we had
instead minimized the residual in the dual secant equation?

~ Math
\min_{\beta_k} \norm{\beta_k^{-1} \vy_k - \vs_k}_2^2
~

~ Align
0 &\overset{!}{=}
\pdv{\beta_k} \norm{\beta_k^{-1} \vy_k - \vs_k}_2^2 \\
&= \pdv{\beta_k} \qty[\beta_k^{-2} \vy_k^T \vy_k - 2 \beta_k^{-1} \vs_k^T \vy_k + \vs_k^T \vs_k] \\
&= -2 \beta_k^{-3} \vy_k^T \vy_k + 2 \beta_k^{-2} \vs_k^T \vy_k \\
&= -2 \beta_k^{-3} \qty[\vy_k^T \vy_k - \beta_k \vs_k^T \vy_k]
~

~ Math
\implies\quad \beta_k = \frac{\vy_k^T \vy_k}{\vs_k^T \vy_k}
~

This alternative optimal value of $\beta_k$ gives rise to a new iterative formula, called the ___dual Barzilai--Borwein method___.

~ Well
~~ Math { .mt-2; .mb-0; }
\vx_{k+1} = \vx_k - \frac{\vs_k^T \vy_k}{\vy_k^T \vy_k} \vg_k
~~
~


Observe that this method is nearly identical to the original Barzilai--Borwein method, except that the original scaling factor $\beta_k$ has been replaced by its reciprocal $\beta_k^{-1},$ and the vectors $\vs_k$ and $\vy_k$ have been interchanged. This makes perfect sense, because the dual secant equation $B_k^{-1} \vy_k = \vs_k$ is nothing more than the primal secant equation $B_k \vs_k = \vy_k$ after replacing $B_k$ by $B_k^{-1}$ and exchanging the roles of $\vs_k$ and $\vy_k.$ This observation leads us to the following ___principle of duality___:

~ Well
__Principle of duality__: Given any quasi-Newton optimization method in which the approximate Hessian $B_k$ is constructed from $\vs_k$ and $\vy_k,$ we obtain its corresponding ___dual method___ by swapping $B_k \leftrightarrow B_k^{-1}$ and $\vs_k \leftrightarrow \vy_k.$
~

The two Barzilai--Borwein methods we have just derived constitute our first example of a primal/dual pair of quasi-Newton methods.

-----

Symmetric first-order update ansatz: $B_k = B_{k-1} - \vu \vu^T$

Impose the primal secant equation: $B_k \vs_k = \vy_k$

$\norm{\qty(B_{k-1} - \vu \vu^T) \vs_k - \vy_k}_2$

$\norm{\qty(B_{k-1} \vs_k - \vy_k) - \vu \vu^T \vs_k}_2$

$\displaystyle \vu = \frac{B_{k-1} \vs_k - \vy_k}{\sqrt{\vs_k^T \qty(B_{k-1} \vs_k - \vy_k)}}$

$\displaystyle B_k = B_{k-1} - \frac{\qty(B_{k-1} \vs_k - \vy_k) \qty(B_{k-1} \vs_k - \vy_k)^T}{\vs_k^T \qty(B_{k-1} \vs_k - \vy_k)}$

$\displaystyle B_k^{-1} = \qty(B_{k-1} - \vu \vu^T)^{-1} = B_{k-1}^{-1} + \frac{B_{k-1}^{-1} \vu \vu^T B_{k-1}^{-1}}{1 - \vu^T B_{k-1}^{-1} \vu} = B_{k-1}^{-1} + \vv \vv^T$

$\displaystyle \vv = \frac{B_{k-1}^{-1} \vu}{\sqrt{1 - \vu^T B_{k-1}^{-1} \vu}}$

$\displaystyle B_{k-1}^{-1} \vu = \frac{\vs_k - B_{k-1}^{-1} \vy_k}{\sqrt{\vs_k^T \qty(B_{k-1} \vs_k - \vy_k)}}$

$\displaystyle \vu^T B_{k-1}^{-1} \vu = \frac{\vs_k^T B_{k-1} \vs_k + \vy_k^T B_{k-1}^{-1} \vy_k - 2 \vs_k^T \vy_k}{\vs_k^T \qty(B_{k-1} \vs_k - \vy_k)}$

$\displaystyle 1 - \vu^T B_{k-1}^{-1} \vu = \frac{\vs_k^T \vy_k - \vy_k^T B_{k-1}^{-1} \vy_k}{\vs_k^T \qty(B_{k-1} \vs_k - \vy_k)}$

$\displaystyle \vv = \frac{\vs_k - B_{k-1}^{-1} \vy_k}{\sqrt{\vy_k^T \qty(\vs_k - B_{k-1}^{-1} \vy_k)}}$

$\displaystyle B_k^{-1} = B_{k-1}^{-1} + \frac{\qty(\vs_k - B_{k-1}^{-1} \vy_k) \qty(\vs_k - B_{k-1}^{-1} \vy_k)^T}{\vy_k^T \qty(\vs_k - B_{k-1}^{-1} \vy_k)}$

This shows that the SR1 method is self-dual.

-----

~ Definition
A connected (pseudo-)Riemannian manifold $M$ is said to be ___extensible___ if $M$ can be isometrically embedded as an open submanifold of a strictly larger connected (pseudo-)Riemannian manifold. Otherwise, we say that $M$ is ___inextensible___ or ___maximal___.
~

~ LongWell
**Hopf--Rinow Theorem:** Let $M$ be a connected Riemannian manifold. The following are equivalent:

1. $M$ is geodesically complete.
2. $M$ is geodesically complete at some point $p \in M.$
3. $M$ has the Heine--Borel property.
4. $M$ is complete as a metric space.

Moreover, if any of these statements hold, then there exists a length-minimizing geodesic joining any two points of $M.$
{ margin: 0px; }
~

----

We denote by $\Ord$ the class of ordinal numbers. Following von Neumann's construction, we identify each ordinal number $\alpha \in \Ord$ with the transitive set of all smaller ordinals, well-ordered with respect to the set membership relation ${\in}.$

~ Definition
A ***surreal number*** is a function from an ordinal number to the 2-element set $\{+, -\}.$ The class of surreal numbers is denoted by $\No.$
~

Clearly, there are at least as many surreal numbers as ordinal numbers, so $\No$ is a proper class. We will later see that $\Ord$ embeds into $\No$ in a natural way.

~ Begin Notation { #birthday; label: "birthday"; }
The domain of a surreal number $x \in \No$ is called its ***birthday***, denoted by $\beta(x).$
~ End Notation

Conway imagines that the surreal numbers are constructed inductively, with the empty sequence $()$ being created on "day zero." (Recall that in von Neumann's construction, the empty set is the ordinal number zero.) On day one, its descendants $(+)$ and $(-)$ are born via concatenation of a ${+}$ or ${-}.$ Then, on day two, $(+)$ gives birth to $(++)$ and $(+-)$, while $(-)$ gives birth to $(-+)$ and $(--).$ Continuing in this fashion, $2^n$ new surreal numbers are born on the $n$^th^ day. This process continues transfinitely, with $2^\alpha$ new surreal numbers born on each day $\alpha \in \Ord.$

~ Begin Definition
We say that a surreal number $x \in \No$ is ***simpler*** than a surreal number $y \in \No,$ denoted by $x \simplereq y,$ if $x$ is an initial segment of $y.$ We write $x \simpler y$ to mean $x \simplereq y$ and $x \ne y.$
~ End Definition

~ MathCard
~~ TheoremBody
Let $F, G \subset \No$ be sets of surreal numbers. (Note that this notation indicates that $F$ and $G$ are sub_sets_ of $\No,$ as opposed to sub_classes_.) If $F < G,$ then there exists a unique simplest surreal number $x \in \No$ satisfying $F < x < G.$
~~
~~ LongProofSketchBody
If $F = G = \varnothing,$ then we take the empty sequence. If $F$ is non-empty but $G$ is empty, then we take a sufficiently long sequence of $+;$ similarly, if $F$ is empty but $G$ is non-empty, then we take a sufficiently long sequence of $-.$

If both $F$ and $G$ are non-empty, then there exists a least ordinal $\alpha$ such that any member of $F$ differs from any member of $G$ somewhere in their first $\alpha$ places. (Indeed, if there were no such $\alpha,$ then there would exist a member of $F$ that agrees with a member of $G$ in _every_ place, contradicting our assumption that $F < G.$) Because we picked $\alpha$ to be the _least_ such ordinal, for every $\gamma < \alpha,$ there exist members of $F$ and $G$ who agree in their first $\gamma$ places. This uniquely determines $x(\gamma)$ for all $\gamma < \alpha.$

We now consider two cases. If $\alpha$ is a limit ordinal, then we have a well-defined surreal number $x: \alpha \to \{{+}, {-}\}.$ If $x \notin F$ and $x \notin G,$ then $x$ works; otherwise, either $x \in F$ or $x \in G,$ but not both (since $F < G$). If $x \in F,$ then we append just enough $+$ signs to get a number that exceeds $F;$ similarly with $-$ signs for $G.$

On the other hand, if $\alpha$ is a successor ordinal, then we have a well-defined surreal number $x: (\alpha - 1) \to \{{+}, {-}\}.$ Let $F'$ denote the set of tails of $x$ in $F,$ and let $G'$ denote the set of tails of $x$ in $G.$ Note that neither $F'$ nor $G'$ are empty, since by construction, $x$ has tails in both $F$ and $G$ (even if the only tail is the empty tail). By the definition of $\alpha,$ for any $a \in F'$ and $b \in G',$ we have $a(0) < b(0).$ If neither $F'$ nor $G'$ contains the empty sequence, then $a(0) = {-}$ and $b(0) = {+},$ so $x$ works. Otherwise, suppose $F'$ contains the empty sequence. We append a single ${+}$ to $x$ to exceed $F,$ followed by just enough ${-}$ signs to slip under $G.$
~~
~

~ Notation
Given $F, G \subset \No$ with $F < G,$ we denote by $F \mid G$ the simplest surreal number $x \in \No$ satisfying $F < x < G.$ We call the pair of sets $(F, G)$ a ___representation___ of $x,$ and write $x = F \mid G.$
~

~ Theorem
Let $F, G \subset \No$ with $F < G,$ and let $\alpha$ be the least ordinal for which $\beta(x) < \alpha$ for all $x \in F \cup G.$ Then $\beta(F \mid G) \le \alpha.$
~

Note that the inequality $\beta(x) < \alpha$ in the statement of the preceding theorem cannot be replaced by $\beta(x) \le \alpha.$ Indeed, if $F = \{(+)\}$ and $G = \{(++)\},$ then $F \mid G = ({+}{+}{-}).$

~ Definition
The ___canonical representation___ of a surreal number $x \in \No$ is the representation $x = F \mid G$ where $F$ is the set of initial segments of $x$ which are less than $x$ itself, and $G$ is the set of initial segments of $x$ exceeding $x.$
~

~ Definition
~~ Math { margin: 0px; }
a + b \coloneqq \{ a^L + b,\ a + b^L \} \mid \{ a^R + b,\ a + b^R \}
~~
~

~ Definition
We say that two positive surreal numbers $x, y \in \No$ are in the same ***Archimedean class***, denoted by $x \sim y,$ if there exists an integer $n \in \N$ such that $nx \ge y$ and $x \le ny.$ On the other hand, if $nx < y$ for all $n \in \N,$ we write $x \ll y,$ or equivalently, $y \gg x.$
~

For any two positive surreal numbers $x, y \in \No,$ we either have $x \ll y,$ $x \sim y,$ or $x \gg y.$

~ Definition
~~ Math { margin: 0px; }
\omega^x \coloneqq \{ 0, 2^n \omega^{x^L} \} \mid \{ 2^{-n} \omega^{x^R} \}
~~
~

~ LongTheorem
Let $x, y \in \No$.
{ .mb-1; }

* $\omega^x > 0.$
* $x < y$ if and only if $\omega^x \ll \omega^y.$
* $\omega^0 = 1.$
* $\omega^{x+y} = \omega^x \omega^y.$
* If $x$ is an ordinal, then $\omega^x$ agrees with ordinal exponentiation in the usual sense.
{ .mb-0; }
~

~ Theorem
A positive surreal number is the simplest element of its Archimedean class if and only if it can be written in the form $\omega^x$ for some $x \in \No$.
~

~ MathCard
~~ LongTheoremBody
Every surreal number $x \in \No$ admits a unique representation in the form
~~~ Math
x = \sum_{\alpha < \beta} r_\alpha \omega^{y_\alpha}
~~~
where $\beta \in \Ord,$ $(y_\alpha)_{\alpha < \beta}$ is a strictly decreasing sequence of surreal numbers, and $(r_\alpha)_{\alpha < \beta}$ is a sequence of nonzero real numbers. If $x$ is an ordinal, then this representation coincides with the Cantor normal form.
{ margin: 0px; }
~~
~~ DefinitionBody
This representation is called the ___Conway normal form___ of $x.$
~~
~~ ProofSketchBody
The technique is somewhat analogous to the algorithm for computing continued fractions. Repeatedly extract the largest Archimedean class from $x,$ and show that this procedure must terminate at some transfinite stage.
~~
~

It follows from the existence of Conway normal forms that every surreal number can be uniquely written as the sum of a real number (the $\omega^0$ term), an infinitesimal number (the terms with negative exponents), and a purely infinite number (the terms with positive exponents).

~ LongDefinition
For $x, y \in \No,$ let $r_y(x)$ denote the real-valued coefficient of $\omega^y$ in the Conway normal form of $x$, with $r_y(x) \coloneqq 0$ if $\omega^y$ does not occur. We say that a sequence $(x_n)_{n \in \N}$ of surreal numbers ___converges___ to $x,$ denoted by $x = \lim_{n \to \infty} x_n,$ if $r_y(x) = \lim_{n \to \infty} r_y(x_n)$ for all $y \in \No.$

If, for each fixed $y,$ the sequence $r_y(x_n)$ is eventually constant, then we say that $(x_n)_{n \in \N}$ ___converges absolutely___ to $x.$
{ margin: 0px; }
~

Note that any (possibly multivariate) formal power series with real coefficients, even if wildly divergent on real-valued arguments, is absolutely convergent when fed infinitesimal surreal arguments.

This suggests a powerful design pattern for extending real functions $f: \R \to \R$ to the surreals.

* Split a surreal number $x \in \No$ into infinitesimal, real, and purely infinite parts.
* Use any power series, even a divergent power series, to define $f$ on infinitesimals.
* Define $f$ as usual on the reals.
* Find an inductive definition of $f$ on purely infinite numbers, say, of the form $\omega^y.$

This strategy is used in [this paper](https://arxiv.org/pdf/1505.02478.pdf) to extend the natural logarithm to $\No.$

-----

There exists a field called _constructive gravity_ dedicated to the following question: given a collection of equations describing the dynamics of a matter field, what is the corresponding diffeomorphism-invariant theory of gravity? That is, what tensor fields are required to describe the spacetime geometry to which this matter couples, and what field equations do those tensor fields satisfy?

The methods of constructive gravity can describe more general spacetime geometries than the Lorentzian metrics of standard general relativity. For example, there are so-called _area metric manifolds_ which, instead of carrying a metric $g_{ab}$ which measures tangent lengths, carry an _area metric_ $G_{abcd}$ which measures tangent areas. Such a geometry is required to describe a spacetime in which [light can spontaneously birefract](http://dx.doi.org/10.1088/0264-9381/26/3/035024).

* [Gravitational Closure of Matter Field Equations](https://doi.org/10.1103/PhysRevD.97.084036)
* [Covariant constructive gravity: A step-by-step guide towards alternative theories of gravity](https://doi.org/10.1103/PhysRevD.101.084025)
* [Gravitational dynamics for all tensorial spacetimes carrying predictive, interpretable, and quantizable matter](http://dx.doi.org/10.1103/PhysRevD.85.104042)

-----

~ Math
\begin{aligned}
x &= r \sin(\theta) \cos(\phi) \\
y &= r \sin(\theta) \sin(\phi) \\
z &= r \cos(\theta)
\end{aligned}
~

-----

~ Math
\begin{aligned}
\pdv{x}{r} &= \sin(\theta) \cos(\phi) &
\pdv{x}{\theta} &= r \cos(\theta) \cos(\phi) &
\pdv{x}{\phi} &= -r \sin(\theta) \sin(\phi) \\
\pdv{y}{r} &= \sin(\theta) \sin(\phi) &
\pdv{y}{\theta} &= r \cos(\theta) \sin(\phi) &
\pdv{y}{\phi} &= r \sin(\theta) \cos(\phi) \\
\pdv{z}{r} &= \cos(\theta) &
\pdv{z}{\theta} &= -r \sin(\theta) &
\pdv{z}{\phi} &= 0
\end{aligned}
~

-----

~ Definition
Let $M$ be a smooth manifold. A ***tangent vector*** at a point $p \in M$ is an $\R$-linear map $X_p : C^\infty(M) \to \R$ satisfying the _Leibniz identity_
~~ Math
X_p(f g) = X_p(f) g(p) + f(p) X_p(g).
~~
The set of all tangent vectors at the point $p$ is called the ***tangent space*** at $p,$ denoted by $T_p M.$
{ margin: 0px; }
~

[INCLUDE=DZFooter.mdk]
